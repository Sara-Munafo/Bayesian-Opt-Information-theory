{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changes to common parts\n",
    "\n",
    "### 1.plot_3d_surface_variance, \n",
    "- didn't work with matriX, went back to x1,x2\n",
    "- added folder path and name parameters to save the image (import kaleido)\n",
    "\n",
    "\n",
    "### 2. make_gif\n",
    "- Added 'duration' parameter to make_gif (and also in NN training as 'gif_dur', so that the duration of each frame can be changed )   \n",
    "\n",
    "### 3. plot\n",
    "- Added lines to plot_MLP to plot everything in the function (some lines for the plot were still in the NN training)\n",
    "\n",
    "**We can use a parameter 'name' in training as the name of the gif when we are in 1d or the name of the image when we are in 2d**\n",
    "\n",
    "# Changes to NN training\n",
    "- Removed parameter 'optimizer'  from NN training, since we only do NN training with smc\n",
    "- changed minor things in training that were giving some errors (like fixed the way to determine the number of parameters)\n",
    "- added parameter 'name' instead of 'name_gif'which can be either the name of the gif if in 1d or the name of the 3d surface plot if 2d\n",
    "- removed parameter 'k_dim' used for smc: if we find the dimension d with x.shape[1], k_dim=d+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image            \n",
    "import os\n",
    "import imageio                    \n",
    "from IPython.display import display, Image\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor \n",
    "from sklearn.gaussian_process.kernels import Matern      \n",
    "import plotly.graph_objects as go\n",
    "import kaleido\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquisition function\n",
    "def prob_i(x, gp_model, best_y):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        x (_type_): _description_\n",
    "        gp_model (_type_): _description_\n",
    "        best_y (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"    \n",
    "    if len(x.shape)==1 or x.shape[1]==1:\n",
    "        y_pred, y_std = gp_model.predict(x.reshape(-1, 1), return_std=True)\n",
    "    else:\n",
    "        y_pred, y_std = gp_model.predict(x, return_std=True)\n",
    "    z = (y_pred - best_y) / y_std\n",
    "    pi = norm.cdf(z)\n",
    "    return pi\n",
    "\n",
    "def expected_i(x, gp_model, best_y):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        x (_type_): _description_\n",
    "        gp_model (_type_): _description_\n",
    "        best_y (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"    \n",
    "    if len(x.shape)==1 or x.shape[1]==1:\n",
    "        y_pred, y_std = gp_model.predict(x.reshape(-1, 1), return_std=True)\n",
    "    else:\n",
    "        y_pred, y_std = gp_model.predict(x, return_std=True)\n",
    "    z = (y_pred - best_y) / y_std\n",
    "    ei = (y_pred - best_y) * norm.cdf(z) + y_std * norm.pdf(z)\n",
    "    return ei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smc(x,y,N,k_dim,T, var):\n",
    "    '''Parameters:\n",
    "    \n",
    "    - x = sample of x\n",
    "    - y = sample of y\n",
    "    - N = number of samples for smc\n",
    "    - k_dim = number of hyperparameters\n",
    "    - T = \n",
    "    - var = T/100\n",
    "    \n",
    "    Output: theta_best = optimized hyperparameters'''\n",
    "    \n",
    "    #inizialization\n",
    "    theta = np.zeros((N,k_dim,T))\n",
    "    theta[:,:,0] = np.full((N,k_dim), 10) #to avoid negative theta we start far from 0\n",
    "    w = np.zeros((N,T))\n",
    "    \n",
    "    \n",
    "    for t in range(1, T):\n",
    "        for i in range(N):\n",
    "            for j in range(k_dim):\n",
    "                theta[i,j,t] = np.random.normal(loc=theta[i,j,t-1], scale=var[j])\n",
    "            \n",
    "            \n",
    "            #compute weights (gp needs to be computed with each set of hyperpars)\n",
    "            if k_dim==2:\n",
    "                kernel = (theta[i,0,t]**2) * Matern(length_scale=theta[i,1,t], nu=1.5)\n",
    "                gp = GaussianProcessRegressor(kernel=kernel, optimizer=None, alpha=1e-5)\n",
    "                gp.fit(x.reshape(-1, 1),y)\n",
    "            elif k_dim==3:\n",
    "                kernel = (theta[i,0,t]**2) * Matern(length_scale=[theta[i,1,t],theta[i,2,t]], nu=1.5)\n",
    "                gp = GaussianProcessRegressor(kernel=kernel, optimizer=None, alpha=1e-5)\n",
    "                gp.fit(x,y)\n",
    "                \n",
    "            w[i,t] = np.exp(gp.log_marginal_likelihood()*1e-3) #scaled to avoid underflow; will be normalized, so no worry\n",
    "\n",
    "        #normalize weights\n",
    "        w[:,t]/=np.sum(w[:,t])\n",
    "        \n",
    "        '''start resampling'''\n",
    "        #print(w[:,t])\n",
    "        #resample with replacement:\n",
    "        for i in range(N):\n",
    "            index = np.random.choice(N, size=1, p=w[:,t])\n",
    "            theta[i,:,t] = theta[index,:,t]\n",
    "        \n",
    "    theta_best = np.mean(theta[:,:,T-1], axis=0)\n",
    "    return theta_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from Classes import BlackBox\n",
    "# forse meglio fare un file con la classe?\n",
    "class BlackBox:\n",
    "    def __init__(self):\n",
    "        \"\"\"_summary_\n",
    "        \"\"\"        \n",
    "        #Branin\n",
    "        self.a = 1.0\n",
    "        self.b = 5.1 / (4.0 * (np.pi ** 2))\n",
    "        self.c = 5.0 / np.pi\n",
    "        self.r = 6.0\n",
    "        self.s = 10.0\n",
    "        self.t = 1 / (8.0 * np.pi)\n",
    "        \n",
    "        #hartman 3d\n",
    "        self.alpha = np.array([1.0, 1.2, 3.0, 3.2], dtype=float)\n",
    "        \n",
    "        self.P = 10**(-4) * np.array([[3689, 1170, 2673],\n",
    "                 [4699, 4387, 7470],\n",
    "                 [1091, 8732, 5547],\n",
    "                 [381, 5743, 8828]],dtype=float)\n",
    "        \n",
    "        self.A = np.array([[3.0, 10, 30],\n",
    "                 [0.1, 10, 35],\n",
    "                 [3.0, 10, 30],\n",
    "                 [0.1, 10, 35]], dtype=float)\n",
    "\n",
    "        \n",
    "    @staticmethod        \n",
    "    def simple_func(x: np.ndarray)-> np.ndarray:\n",
    "        y = np.sin(x) + np.cos(2*x)\n",
    "        return y\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def branin(x1: np.ndarray,\n",
    "               x2: np.ndarray,\n",
    "                a: float, \n",
    "                b: float, \n",
    "                c: float, \n",
    "                r: float, \n",
    "                s: float, \n",
    "                t: float) -> np.ndarray:\n",
    "        Hb = np.zeros_like(x1, dtype=float)\n",
    "        Hb = a * (x2 - b * (x1 ** 2) + c * x1 - r) ** 2 + s * (1 - t) * np.cos(x1) + s\n",
    "        return Hb\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_y_values(xx: np.ndarray, alpha: np.ndarray, A, P)-> float:\n",
    "        '''\n",
    "        input: \n",
    "            xx = c(x1, x2, x3)\n",
    "        \n",
    "        parameters:\n",
    "            self.alpha\n",
    "            self.P\n",
    "            self.A\n",
    "        '''\n",
    "        outer = 0.0\n",
    "        for ii in range(4):\n",
    "            inner = 0\n",
    "            for jj in range(3):\n",
    "                xj = xx[jj]\n",
    "                Aij = A[ii, jj]\n",
    "                Pij = P[ii, jj]\n",
    "                inner += Aij * (xj - Pij) ** 2\n",
    "            new = alpha[ii] * np.exp(-inner)\n",
    "            outer += new\n",
    "        y = -outer\n",
    "        return y\n",
    "    \n",
    "    @classmethod\n",
    "    def hartmann3d(cls, x1: np.ndarray, \n",
    "                   x2: np.ndarray,\n",
    "                   x3: np.ndarray, \n",
    "                   n: int, \n",
    "                   alpha: np.ndarray, \n",
    "                   A: np.ndarray, \n",
    "                   P: np.ndarray)->np.ndarray:\n",
    "        \n",
    "        y_values = np.zeros((n, n, n))\n",
    "        for i, x1_val in enumerate(x1):\n",
    "            for j, x2_val in enumerate(x2):\n",
    "                for k, x3_val in enumerate(x3):\n",
    "                    y = cls.compute_y_values( np.array([x1_val, x2_val, x3_val]), alpha, A, P)\n",
    "                    y_values[i, j, k] = y\n",
    "        return y_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(matriX: np.ndarray, n_sample: int, a: float, b: float, c: float, r: float, s: float, t: float )-> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        matriX (np.ndarray): _description_\n",
    "        n_sample (int): _description_\n",
    "        a (float): _description_\n",
    "        b (float): _description_\n",
    "        c (float): _description_\n",
    "        r (float): _description_\n",
    "        s (float): _description_\n",
    "        t (float): _description_\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, np.ndarray]: _description_\n",
    "    \"\"\"\n",
    "    s_x = np.zeros((n_sample,2), dtype=float)\n",
    "    s_x[:,0] = np.random.choice(matriX[:,0], n_sample)\n",
    "    s_x[:,1] = np.random.choice(matriX[:,1], n_sample)\n",
    "    \n",
    "    s_z = np.zeros_like(s_x, dtype=float)\n",
    "    s_z = my_blackbox.branin(s_x[:,0], s_x[:,1], a=a, b=b, c=c, r=r, s=s, t=t)\n",
    "\n",
    "    return s_x, s_z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLOT FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_1D(matriX, my_blackbox, improv, y_pred, y_std, sample_x, sample_y):\n",
    "    plt.plot(matriX, my_blackbox.simple_func(matriX), color='orange', label='Black Box Function', linewidth=2, alpha=0.7)\n",
    "    plt.plot(matriX, 10*improv, color='red', linestyle='dashed', label='10 x Surrogate Function', alpha=0.8)\n",
    "    plt.fill_between(matriX, y_pred - 2*y_std, y_pred + 2*y_std, color='blue', alpha=0.2)\n",
    "    plt.plot(matriX, y_pred, color='blue', label='Gaussian Process', alpha=0.7, linewidth=2)\n",
    "    plt.scatter(sample_x, sample_y, color='red', label='Previous Points')\n",
    "\n",
    "\n",
    "\n",
    "def plot_MLP(matriX, y_pred, y_std, sample_x, sample_y,i):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        matriX (_type_): _description_\n",
    "        y_pred (_type_): _description_\n",
    "        y_std (_type_): _description_\n",
    "        sample_x (_type_): _description_\n",
    "        sample_y (_type_): _description_\n",
    "    \"\"\"    ''''''\n",
    "    plt.fill_between(matriX, y_pred - 2*y_std, y_pred + 2*y_std, color='blue', alpha=0.2)\n",
    "    plt.plot(matriX, y_pred, color='blue', label='Gaussian Process', alpha=0.7, linewidth=2)\n",
    "    plt.scatter(sample_x[:-1], sample_y[:-1], color='red', label='Previous Points')\n",
    "    plt.scatter(sample_x[-1],sample_x[-1], color='green', label='New Points')\n",
    "    plt.xlabel('x')\n",
    "    plt.ylabel('y')\n",
    "    plt.title(f\"Iteration #{i+1}\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    \n",
    "\n",
    "def plot_3d_surface_variance(x1,x2, y_values, y_std, folder_path, name):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        matriX (_type_): _description_\n",
    "        y_values (_type_): _description_\n",
    "        y_std (_type_): _description_\n",
    "    \"\"\"    \n",
    "    \n",
    "    y_values_reshaped = y_values.reshape(x1.shape)\n",
    "    y_std_reshaped = y_std.reshape(x1.shape)\n",
    "\n",
    "    fig = go.Figure(data=[go.Surface(x=x1, y=x2, z=y_values_reshaped, colorscale='Viridis', name='ypred')])\n",
    "\n",
    "    fig.add_trace(go.Surface(x=x1, y=x2, z=y_values_reshaped + y_std_reshaped, colorscale='Viridis',showscale=False, opacity=0.6, name='ypred + y_std'))\n",
    "    fig.add_trace(go.Surface(x=x1, y=x2, z=y_values_reshaped - y_std_reshaped, colorscale='Viridis',showscale=False, opacity=0.6, name='ypred - y_std'))\n",
    "\n",
    "    # Set layout\n",
    "    fig.update_layout(scene=dict(\n",
    "                        xaxis_title='Learning rate',\n",
    "                        yaxis_title='Batch size',\n",
    "                        zaxis_title='Acquisition function'))\n",
    "    \n",
    "    # Show plot\n",
    "    fig.show()\n",
    "    fig_path = os.path.join(folder_path, name)\n",
    "    fig.write_image(fig_path)\n",
    "\n",
    "\n",
    "def make_gif(folder_path, frames,name,duration):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        folder_path (_type_): _description_\n",
    "        frames (_type_): _description_\n",
    "        name (_type_): _description_\n",
    "    \"\"\"    \n",
    "    gif_path = os.path.join(folder_path, name)\n",
    "\n",
    "    with imageio.get_writer(gif_path, mode='I', duration=duration) as writer:\n",
    "        for frame in frames:\n",
    "            image = imageio.imread(os.path.join(folder_path, frame))\n",
    "            writer.append_data(image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blackbox_mlp(theta, X_train,y_train, X_test,y_test):\n",
    "    '''Parameters:\n",
    "        - theta: 2D array\n",
    "          - theta[0] : learning rate\n",
    "          - theta[1] : batch size\n",
    "    '''\n",
    "    if len(theta)==2:\n",
    "        mlp = MLPClassifier(max_iter=100, alpha=1e-4, solver='sgd',\n",
    "                        tol=1e-4, random_state=2072380, learning_rate_init=theta[0], hidden_layer_sizes=(20,20),\\\n",
    "                            batch_size=int(theta[1])).fit(X_train,y_train)\n",
    "        mlp.predict(X_test)\n",
    "    \n",
    "    if len(theta)==1:\n",
    "        mlp = MLPClassifier(max_iter=100, \n",
    "                            alpha=1e-4, \n",
    "                            solver='sgd',\n",
    "                            tol=1e-4, \n",
    "                            random_state=2072380, \n",
    "                            learning_rate_init=theta[0], \n",
    "                            hidden_layer_sizes=(20,20)).fit(X_train,y_train)\n",
    "        mlp.predict(X_test) \n",
    "    return mlp.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_MLP(x_grid,\n",
    "                    x,\n",
    "                    y,\n",
    "                    x1,\n",
    "                    x2,\n",
    "                    num_iterations, \n",
    "                    acquisition, \n",
    "                    N, \n",
    "                    T, \n",
    "                    var,  \n",
    "                    folder_path:str, \n",
    "                    name:str,\n",
    "                    gif_dur):\n",
    "    \"\"\"_summary_\n",
    "\n",
    "    Args:\n",
    "        x_grid (_type_): grid for x locations (1d or 2d)\n",
    "        x : sample of x points\n",
    "        y (_type_): observed sample values\n",
    "        x1 (_type_): _description_\n",
    "        x2 (_type_): _description_\n",
    "        num_iterations (_type_): _description_\n",
    "        acquisition (_type_): _description_\n",
    "        N (_type_): _description_\n",
    "        T (_type_): _description_\n",
    "        var (_type_): _description_\n",
    "        k_dim (_type_): _description_\n",
    "        folder_path: folder to save images and gifs in\n",
    "        name: name of 1d gif or 2d plot\n",
    "        gif_dur: length of each frame in 1d gif\n",
    "    \"\"\"    \n",
    "\n",
    "\n",
    "    #dimension of parameters vector\n",
    "    d = x.shape[1]\n",
    "    theta_best = [1.0]*(d+1) #initial hyperpars of kernel\n",
    "    \n",
    "    #set plot for 1d gif:\n",
    "    if (d==1):\n",
    "        frames = []\n",
    "        plt.figure(figsize=(10, 6))\n",
    "    \n",
    "        \n",
    "    for i in range(num_iterations):\n",
    "        if (i%10==0):\n",
    "            print('Iteration number : ', i)\n",
    "\n",
    "        #Manually update kernel hyperparameters\n",
    "        kernel = theta_best[0]**2 * Matern(length_scale=theta_best[1:], nu=1.5)\n",
    "        gp_model = GaussianProcessRegressor(kernel=kernel, alpha=1e-5, optimizer= None)\n",
    "            \n",
    "        # Fit the Gaussian process model to the sampled points\n",
    "        gp_model.fit(x.reshape(-1,d),y)\n",
    "    \n",
    "        # Determine the point with the highest observed function value\n",
    "        best_idx = np.argmax(y)\n",
    "        best_x = x[best_idx]\n",
    "        best_y = y[best_idx]\n",
    "    \n",
    "        # Generate the acquisition function using the Gaussian process model\n",
    "        y_pred, y_std = gp_model.predict(x_grid.reshape(-1,d), return_std=True)\n",
    "                                         \n",
    "        if acquisition==0:\n",
    "            improv = expected_i(x_grid.reshape(-1, d),gp_model,best_y)\n",
    "        else:\n",
    "            improv = prob_i(x_grid.reshape(-1, d),gp_model,best_y)\n",
    "            \n",
    "        \n",
    "        if i < num_iterations - 1:\n",
    "            new_x = x_grid[np.argmax(improv)].reshape(-1,d)  # Select the next point based on\n",
    "            new_y = blackbox_mlp(new_x[0],X_train,y_train, X_test,y_test)\n",
    "            x = np.concatenate((x, new_x))\n",
    "            y = np.append(y, new_y)\n",
    "        \n",
    "\n",
    "        #Optimize hyperpars with smc\n",
    "        theta_best = smc(x,y,N,d+1,T,var)\n",
    "        \n",
    "        # Save frame for 1d gif\n",
    "        if x.shape[1]==1:\n",
    "            plot_MLP(x_grid, y_pred, y_std, x, y, i)\n",
    "            filename = f\"frame_{i}.png\"\n",
    "            plt.savefig(os.path.join(folder_path, filename))\n",
    "            frames.append(filename)\n",
    "            plt.clf()  # Clear current figure\n",
    "    \n",
    "\n",
    "\n",
    "    if x.shape[1]==1:\n",
    "    # Create the GIF using the frames saved in the specified folder\n",
    "        make_gif(folder_path, frames, name, gif_dur)\n",
    "        # Remove the saved frames\n",
    "        for frame_file in frames:\n",
    "            os.remove(os.path.join(folder_path, frame_file))\n",
    "    if x.shape[1]==2:\n",
    "        # Final plot\n",
    "        plot_3d_surface_variance(x1,x2, y_pred,y_std, folder_path,name)\n",
    "\n",
    "\n",
    "        \n",
    "    print('Optimized theta: ', gp_model.kernel_)\n",
    "    return(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
